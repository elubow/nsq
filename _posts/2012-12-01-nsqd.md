--- 
title: nsqd
layout: post
category: components
permalink: /components/nsqd.html
---

`nsqd` is the daemon that receives, queues, and delivers messages to clients.

It can be run standalone but is normally configured in a cluster with `nsqlookupd` 
instance(s) (in which case it will announce topics and channels for discovery).

It listens on two TCP ports, one for clients and another for the HTTP API.

### Command Line Options

    -broadcast-address="": address that will be registered with lookupd (defaults to the OS hostname)
    -config="": path to config file
    -data-path="": path to store disk-backed messages
    -deflate=true: enable deflate feature negotiation (client compression)
    -e2e-processing-latency-percentile=: message processing time percentiles to keep track of (can be specified multiple times or comma separated, default none)
    -e2e-processing-latency-window-time=10m0s: calculate end to end latency quantiles for this duration of time (ie: 60s would only show quantile calculations from the past 60 seconds)
    -http-address="0.0.0.0:4151": <addr>:<port> to listen on for HTTP clients
    -https-address="": <addr>:<port> to listen on for HTTPS clients
    -lookupd-tcp-address=: lookupd TCP address (may be given multiple times)
    -max-body-size=5123840: maximum size of a single command body
    -max-bytes-per-file=104857600: number of bytes per diskqueue file before rolling
    -max-deflate-level=6: max deflate compression level a client can negotiate (> values == > nsqd CPU usage)
    -max-heartbeat-interval=1m0s: maximum client configurable duration of time between client heartbeats
    -max-message-size=1024768: (deprecated use --max-msg-size) maximum size of a single message in bytes
    -max-msg-size=1024768: maximum size of a single message in bytes
    -max-msg-timeout=15m0s: maximum duration before a message will timeout
    -max-output-buffer-size=65536: maximum client configurable size (in bytes) for a client output buffer
    -max-output-buffer-timeout=1s: maximum client configurable duration of time between flushing to a client
    -max-rdy-count=2500: maximum RDY count for a client
    -mem-queue-size=10000: number of messages to keep in memory (per topic/channel)
    -msg-timeout="60s": duration to wait before auto-requeing a message
    -snappy=true: enable snappy feature negotiation (client compression)
    -statsd-address="": UDP <addr>:<port> of a statsd daemon for pushing stats
    -statsd-interval="60s": duration between pushing to statsd
    -statsd-mem-stats=true: toggle sending memory and GC stats to statsd
    -statsd-prefix="nsq.%s": prefix used for keys sent to statsd (%s for host replacement)
    -sync-every=2500: number of messages per diskqueue fsync
    -sync-timeout=2s: duration of time per diskqueue fsync
    -tcp-address="0.0.0.0:4150": <addr>:<port> to listen on for TCP clients
    -tls-cert="": path to certificate file
    -tls-client-auth-policy="": client certificate auth policy ('require' or 'require-verify')
    -tls-key="": path to private key file
    -tls-required=false: require TLS for client connections
    -tls-root-ca-file="": path to private certificate authority pem
    -verbose=false: enable verbose logging
    -version=false: print version string
    -worker-id=0: unique identifier (int) for this worker (will default to a hash of hostname)

### HTTP API

#### /put or /pub

Publish a message

Params:

    topic - the topic to publish to
    
    POST body - the raw message bytes

{% highlight bash %}
$ curl -d "<message>" http://127.0.0.1:4151/put?topic=message_topic`
{% endhighlight %}

#### /mput or /mpub

Publish multiple messages in one roundtrip

Params:

    topic - the topic to publish to
    
    POST body - `\n` separated raw messages

{% highlight bash %}
$ curl -d "<message>\n<message>\n<message>" http://127.0.0.1:4151/mput?topic=message_topic`
{% endhighlight %}

NOTE: due to the `\n` message separation, this does not currently support binary message formats

#### /create_topic

Create a topic

Params:

    topic - the topic to create

#### /delete_topic

Delete an existing topic (and all channels)

Params:

    topic - the existing topic to delete

#### /create_channel

Create a channel for an existing topic

Params:

    topic - the existing topic
    channel - the channel to create

#### /delete_channel

Delete an existing channel for an existing topic

Params:

    topic - the existing topic
    channel - the existing channel to delete

#### /empty_topic

Empty all the queued messages (in-memory and disk) for an existing topic

Params:

    topic - the existing topic to empty

#### /empty_channel

Empty all the queued messages (in-memory and disk) for an existing channel

Params:

    topic - the existing topic
    channel - the existing channel to empty

#### /pause_topic

Pause message flow to all channels on an existing topic (messages will queue at *topic*)

Params:

    topic - the existing topic

#### /unpause_topic

Resume message flow to channels of an existing, paused, topic

Params:

    topic - the existing topic

#### /pause_channel

Pause message flow to consumers of an existing channel (messages will queue)

Params:

    topic - the existing topic
    channel - the existing channel to pause

#### /unpause_channel

Resume message flow to consumers of an existing, paused, channel

Params:

    topic - the existing topic
    channel - the existing channel to pause

#### /stats

Return internal instrumented statistics

Params

    format - (optional) `text` or `json` (default = `text`)

#### /ping

Monitoring endpoint, should return `OK`

#### /info

Returns version information

#### /debug/pprof

An index page of available debugging endpoints

#### /debug/pprof/profile

Starts a `pprof` CPU profile for 30s and returns the output via the request

**NOTE: this endpoint is *not* listed in the `/debug/pprof` index page because of its effect
on runtime performance and duration**

#### /debug/pprof/goroutine

Returns a stack trace for all running goroutines

#### /debug/pprof/heap

Returns a heap and memstats profile (top portion can be used as a `pprof` memory profile)

#### /debug/pprof/block

Returns a goroutine blocking profile

#### /debug/pprof/threadcreate

Returns goroutine stack traces that led to the creation of an OS thread

### <a name="pprof">Debugging and Profiling</a>

`nsqd` provides a suite of profiling endpoints that integrate directly with Go's [pprof][go_pprof]
tool.  If you have the go tool suite installed, simply run:

{% highlight bash %}
# memory profiling
$ go tool pprof http://localhost:4151/debug/pprof/heap

# cpu profiling
$ go tool pprof http://localhost:4151/debug/pprof/profile
{% endhighlight %}

### TLS

When `nsqd` is configured with `--tls-cert` and `--tls-key` clients can negotiate upgrading their
connection to TLS for enhanced security.

Additionally, you can *require* that clients negotiate TLS with `--tls-required` (as of `nsqd`
`0.2.28+`).

You can configure an `nsqd` client certificate policy via `--tls-client-auth-policy` (`require` or
`require-verify`):

 * `require` - the client must offer a certificate, otherwise rejected
 * `require-verify` - the client must offer a valid certificate according to the default CA
                      or the chain specified by `--tls-root-ca-file`, otherwise rejected

This can be used as a form of client authentication (as of `nsqd` `0.2.28+`).

If you want to generate a password-less self-signed certificate using openssl:

{% highlight bash %}
$ openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes
{% endhighlight %}

### <a name="e2e">End-to-End Processing Latency</a>

You can optionally configure `nsqd` to collect and emit end-to-end message processing
latency for configurable percentiles using the `--e2e-processing-latency-percentile` flag.

The values are calculated using a probabilistic percentile technique described in *[Effective
Computation of Biased Quantiles over Data Streams][bquant]*. We use the [perks][perks] package by
[bmizerany][bmizerany] which implements this algorithm.

In order to bias the view toward more recent processing behavior we only keep quantile information
for the past `N` minutes (configurable via `--e2e-processing-latency-window-time`). Internally we
maintain two quantiles, per channel, that each store `N/2` minutes worth of latency data. Every
`N/2` minutes we reset one quantile (and start inserting new data into it). Since quantiles can be
merged, this results in a coarse rolling window.

Since we only collect data at the *channel* level, for a *topic* we aggregate and merge all
*channel* quantiles. This technique can only be used if the data is on the same `nsqd` instance.
However when data is being accumulated across `nsqd` (for instance via `nsqlookupd`), we take the
average of the quantile values for each `nsqd`. In order to maintain some statistical accuracy
regarding the distribution of latencies across `nsqd`, we also provide the min/max values in
addition to the average.

NOTE: if there are no consumers connected the values cannot update despite there (obviously) being
a slowly increasing end-to-end processing time for the queued messages. This is because end-to-end
metrics are only calculated when `nsqd` receives a `FIN` for a given message from a client. When a
consumer reconnects the values will adjust appropriately.

### <a name="statsd">Statsd / Graphite Integration</a>

When using `--statsd-address` to specify the UDP `<addr>:<port>` for
[statsd](https://github.com/etsy/statsd) (or a port of statsd like
[statsdaemon](https://github.com/bitly/statsdaemon)), `nsqd` will push metrics to statsd
periodically based on the interval specified in `--statsd-interval` (IMPORTANT: this interval should
**always** be less than or equal to the interval at which statsd flushes to graphite). With this
enabled `nsqadmin` can be configured to display charts directly from graphite.

We recommend the following configuration for graphite (but these choices should be evaluated based
on your available resources and requirements). Again, the important piece to remember is that statsd
should flush at an interval less than or equal to the smallest time bucket in `storage-schemas.conf`
and `nsqd` should be configured to flush at or below that same interval via `--statsd-interval`.

{% highlight ini %}
# storage-schemas.conf
[nsq]
pattern = ^nsq\..*
retentions = 1m:1d,5m:30d,15m:1y

# storage-aggregation.conf
[default_nsq]
pattern = ^nsq\..*
xFilesFactor = 0.2 
aggregationMethod = average
{% endhighlight %}

The `nsqd` instance will push to the following `statsd` paths:

    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.backend_depth [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.depth [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.message_count
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.backend_depth [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.clients [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.deferred_count [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.depth [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.in_flight_count [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.message_count
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.requeue_count
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.timeout_count
    
    # if --statsd-mem-stats is enabled
    nsq.<nsqd_host>_<nsqd_port>.mem.heap_objects [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.heap_idle_bytes [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.heap_in_use_bytes [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.heap_released_bytes [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.gc_pause_usec_100 [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.gc_pause_usec_99 [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.gc_pause_usec_95 [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.mem.next_gc_bytes [gauge]
    nsq.<nsqd_host>_<nsqd_port>.mem.gc_runs

    # if --e2e-processing-latency-percentile is specified, for each percentile
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.e2e_processing_latency_<percent> [gauge]
    nsq.<nsqd_host>_<nsqd_port>.topic.<topic_name>.channel.<channel_name>.e2e_processing_latency_<percent> [gauge]

[go_pprof]: http://golang.org/pkg/net/http/pprof/#pkg-overview
[bquant]: http://www.cs.rutgers.edu/~muthu/bquant.pdf
[bmizerany]: https://github.com/bmizerany
[perks]: https://github.com/bmizerany/perks
